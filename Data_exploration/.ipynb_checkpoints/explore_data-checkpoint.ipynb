{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import helperModule as hm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fields = pd.read_csv('Field Names.csv', header=None)\n",
    "field_names = list(fields[0])\n",
    "field_types = fields[1]\n",
    "data_train = pd.read_csv('KDD99Train.csv', names=field_names)\n",
    "data_test = pd.read_csv('KDD99Test.csv', names=field_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              0           1\n",
      "0                      duration  continuous\n",
      "1                 protocol_type    symbolic\n",
      "2                       service    symbolic\n",
      "3                          flag    symbolic\n",
      "4                     src_bytes  continuous\n",
      "5                     dst_bytes  continuous\n",
      "6                          land  continuous\n",
      "7                wrong_fragment  continuous\n",
      "8                        urgent  continuous\n",
      "9                           hot  continuous\n",
      "10            num_failed_logins  continuous\n",
      "11                    logged_in  continuous\n",
      "12              num_compromised  continuous\n",
      "13                   root_shell  continuous\n",
      "14                 su_attempted  continuous\n",
      "15                     num_root  continuous\n",
      "16           num_file_creations  continuous\n",
      "17                   num_shells  continuous\n",
      "18             num_access_files  continuous\n",
      "19            num_outbound_cmds  continuous\n",
      "20                is_host_login  continuous\n",
      "21               is_guest_login  continuous\n",
      "22                        count  continuous\n",
      "23                    srv_count  continuous\n",
      "24                  serror_rate  continuous\n",
      "25              srv_serror_rate  continuous\n",
      "26                  rerror_rate  continuous\n",
      "27              srv_rerror_rate  continuous\n",
      "28                same_srv_rate  continuous\n",
      "29                diff_srv_rate  continuous\n",
      "30           srv_diff_host_rate  continuous\n",
      "31               dst_host_count  continuous\n",
      "32           dst_host_srv_count  continuous\n",
      "33       dst_host_same_srv_rate  continuous\n",
      "34       dst_host_diff_srv_rate  continuous\n",
      "35  dst_host_same_src_port_rate  continuous\n",
      "36  dst_host_srv_diff_host_rate  continuous\n",
      "37         dst_host_serror_rate  continuous\n",
      "38     dst_host_srv_serror_rate  continuous\n",
      "39         dst_host_rerror_rate  continuous\n",
      "40     dst_host_srv_rerror_rate  continuous\n",
      "41                  attack_type    symbolic\n",
      "42            attack_type_index  continuous\n"
     ]
    }
   ],
   "source": [
    "print(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 494021 observations in the training set.\n",
      "There are a total of 311029 observations in the test set.\n",
      "Fields are of type: continuous and of type: symbolic\n",
      "Number of fields of type \"continous\": 39\n",
      "Number of fields of type \"symbolic\": 4\n"
     ]
    }
   ],
   "source": [
    "size_train = len(data_train)\n",
    "size_test = len(data_test)\n",
    "\n",
    "num_fields_train = len(data_train.columns)\n",
    "num_fields_test = len(data_test.columns)\n",
    "unique_field_types = field_types.unique() \n",
    "field_type_count = {field:list(field_types).count(field) for field in unique_field_types}\n",
    "\n",
    "print('There are a total of %d observations in the training set.' % size_train)\n",
    "print('There are a total of %d observations in the test set.' % size_test)\n",
    "print('Fields are of type: %s and of type: %s'   % (unique_field_types[0],unique_field_types[1]))\n",
    "print('Number of fields of type \"continous\": %s' % field_type_count[unique_field_types[0]] )\n",
    "print('Number of fields of type \"symbolic\": %s'  % field_type_count[unique_field_types[1]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 23 attack types in the training set.\n",
      "There are a total of 38 attack types in the test set.\n",
      "Attacks that occur only in the training set are: [warezclient., spy.] \n",
      " \n",
      "Attacks that occur only in the test set are: [snmpgetattack., named., xlock., xsnoop., sendmail., saint., apache2., udpstorm., xterm., mscan., processtable., ps., httptunnel., worm., mailbomb., sqlattack., snmpguess.] \n",
      " \n",
      "Attacks that occur both sets: [normal., buffer_overflow., loadmodule., perl., neptune., smurf., guess_passwd., pod., teardrop., portsweep., ipsweep., land., ftp_write., back., imap., satan., phf., nmap., multihop., warezmaster., rootkit.] \n"
     ]
    }
   ],
   "source": [
    "train_attacks = list(data_train['attack_type'].unique())\n",
    "test_attacks = list(data_test['attack_type'].unique())\n",
    "num_attacks_train = len(train_attacks)\n",
    "num_attacks_test = len(test_attacks)\n",
    "\n",
    "common_attacks_train_test = [attack for attack in train_attacks if attack in test_attacks]\n",
    "unique_attack_train = [attack for attack in train_attacks if attack not in test_attacks]\n",
    "unique_attack_test = [attack for attack in test_attacks if attack not in train_attacks]\n",
    "\n",
    "print('There are a total of %d attack types in the training set.' % num_attacks_train)\n",
    "print('There are a total of %d attack types in the test set.' % num_attacks_test)\n",
    "print('Attacks that occur only in the training set are: [%s] ' % ', '.join(map(str, unique_attack_train)) )\n",
    "print(' ')\n",
    "print('Attacks that occur only in the test set are: [%s] ' % ', '.join(map(str, unique_attack_test)) )\n",
    "print(' ')\n",
    "print('Attacks that occur both sets: [%s] ' % ', '.join(map(str, common_attacks_train_test)) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the train set there are 97278 normal connetions that represent 0.196911 percent of the connections\n",
      "In the test set there are 60593 normal connetions that represent 0.194815 percent of the connections\n",
      "\n",
      "In the train set there are 391458 dos attacks that represent 0.792391 percent of the connections\n",
      "In the test set there are 229853 dos attacks that represent 0.739008 percent of the connections\n",
      "\n",
      "In the train set there are 4107 probe attacks that represent 0.008313 percent of the connections\n",
      "In the test set there are 4166 probe attacks that represent 0.013394 percent of the connections\n",
      "\n",
      "In the train set there are 52 u2r attacks that represent 0.000105 percent of the connections\n",
      "In the test set there are 228 u2r attacks that represent 0.000733 percent of the connections\n",
      "\n",
      "In the train set there are 1126 r2l attacks that represent 0.002279 percent of the connections\n",
      "In the test set there are 16189 r2l attacks that represent 0.052050 percent of the connections\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attacks_train = data_train.ix[:,-2:-1]\n",
    "attacks_test = data_test.ix[:,-2:-1]\n",
    "attacks_train['attack_type'] = attacks_train['attack_type'].str.replace('.', '')\n",
    "attacks_test['attack_type'] = attacks_test['attack_type'].str.replace('.', '')\n",
    "attacks_train, attacks_test = hm.mapAttackTypes(attacks_train, attacks_test)\n",
    "attack_type_groups = attacks_train['attack_type'].unique()\n",
    "\n",
    "attack_count_train = {attack:list(attacks_train['attack_type']).count(attack) for attack in attack_type_groups}\n",
    "attack_count_test = {attack:list(attacks_test['attack_type']).count(attack) for attack in attack_type_groups}\n",
    "\n",
    "print('In the train set there are %d normal connetions that represent %f percent of the connections' % (attack_count_train['NORMAL'], float(attack_count_train['NORMAL'])/float(size_train)))\n",
    "print('In the test set there are %d normal connetions that represent %f percent of the connections' % (attack_count_test['NORMAL'], float(attack_count_test['NORMAL'])/float(size_test)))\n",
    "print('')\n",
    "print('In the train set there are %d dos attacks that represent %f percent of the connections' % (attack_count_train['DOS'], float(attack_count_train['DOS'])/float(size_train)))\n",
    "print('In the test set there are %d dos attacks that represent %f percent of the connections' % (attack_count_test['DOS'], float(attack_count_test['DOS'])/float(size_test)))\n",
    "print('')\n",
    "print('In the train set there are %d probe attacks that represent %f percent of the connections' % (attack_count_train['PROBE'], float(attack_count_train['PROBE'])/float(size_train)))\n",
    "print('In the test set there are %d probe attacks that represent %f percent of the connections' % (attack_count_test['PROBE'], float(attack_count_test['PROBE'])/float(size_test)))\n",
    "print('')\n",
    "print('In the train set there are %d u2r attacks that represent %f percent of the connections' % (attack_count_train['U2R'], float(attack_count_train['U2R'])/float(size_train)))\n",
    "print('In the test set there are %d u2r attacks that represent %f percent of the connections' % (attack_count_test['U2R'], float(attack_count_test['U2R'])/float(size_test)))\n",
    "print('')\n",
    "print('In the train set there are %d r2l attacks that represent %f percent of the connections' % (attack_count_train['R2L'], float(attack_count_train['R2L'])/float(size_train)))\n",
    "print('In the test set there are %d r2l attacks that represent %f percent of the connections' % (attack_count_test['R2L'], float(attack_count_test['R2L'])/float(size_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
