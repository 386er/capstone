{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from pandas import DataFrame, read_csv\n",
    "from sklearn import preprocessing\n",
    "import helperModule as hm\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "############ Read in data\n",
    "#########################\n",
    "\n",
    "data_train, data_test = hm.readData()\n",
    "x_train, y_train, x_test, y_test = hm.splitData(data_train, data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# Mapping of attack types\n",
    "#########################\n",
    "\n",
    "'''\n",
    "38 different attack types are mapped to their corresponding group\n",
    "-----------\n",
    "normal                      ==>   NORMAL\n",
    "unknown                     ==>   UNKNOWN\n",
    "back,land ..                ==>   DOS\n",
    "satan,ipsweep,nmap, ..      ==>   PROBE\n",
    "ftp_write,guess_passwd, ..  ==>   R2L\n",
    "rootkit,perl ..             ==>   U2R\n",
    "-----------\n",
    "'''\n",
    "\n",
    "y_train, y_test = hm.mapAttackTypes(y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "# Feature Encoding\n",
    "##########################\n",
    "\n",
    "'''\n",
    "Categorial features (protocol_types, service, flags) are encoded into integers.\n",
    "-----------\n",
    "protocol_types:\n",
    "['tcp' 'udp' 'icmp']                          ==> [0, 1, 2]\n",
    "service:\n",
    "['ftp_data', 'telnet', ... 'rje', 'harvest']  ==> [0, 1, .... 67, 68]\n",
    "flags:\n",
    "['SF', 'S0', ...  ,'S2', 'OTH']               ==> [ 0, 1 ... , 9, 10]\n",
    "-----------\n",
    "'''\n",
    "\n",
    "x_train = hm.encodeFeatures(x_train)\n",
    "x_test = hm.encodeFeatures(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "# Label Encoding\n",
    "##########################\n",
    "\n",
    "'''\n",
    "5 different attack groups are encoded into integers\n",
    "-----------\n",
    "NORMAL         ==>   0\n",
    "DOS            ==>   1\n",
    "PROBE          ==>   2\n",
    "R2L            ==>   3\n",
    "U2R            ==>   4\n",
    "-----------\n",
    "'''\n",
    "y_train = hm.encodeLabels(y_train)\n",
    "y_test = hm.encodeLabels(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "####### Binarize Labels\n",
    "#########################\n",
    "\n",
    "y_train = hm.binarizeLabels(y_train)\n",
    "y_test = hm.binarizeLabels(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "######### Feature Scaling\n",
    "#########################\n",
    "\n",
    "'''\n",
    "Scale non-categorial features into to values between 0 and 1\n",
    "'''\n",
    "\n",
    "x_train, x_test = hm.scaleFeatures(x_train, x_test) \n",
    "\n",
    "\n",
    "#########################\n",
    "######### Turn data Frame into matrix \n",
    "#########################\n",
    "\n",
    "x_train = x_train.astype(np.float32).values\n",
    "x_test = x_test.astype(np.float32).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_nodes= 512\n",
    "batch_size = 128\n",
    "num_features = 41\n",
    "num_labels = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, num_features))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(x_test)\n",
    "  #tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights_1 = tf.Variable(\n",
    "    tf.truncated_normal([num_features, num_nodes]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_nodes]))\n",
    "  weights_2 = tf.Variable(\n",
    "    tf.truncated_normal([num_nodes, num_labels]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "  # Training computation.\n",
    "  relu_layer=tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "  logits = tf.matmul(relu_layer, weights_2) + biases_2\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "\n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.3).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "   tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1), weights_2) + biases_2)\n",
    "  #test_prediction =  tf.nn.softmax(\n",
    "  #tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1), weights_2) + biases_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 51.888718\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 63.3%\n",
      "Minibatch loss at step 5000: 0.040026\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 10000: 0.048361\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 75.9%\n",
      "Minibatch loss at step 15000: 0.001061\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 20000: 0.002677\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 25000: 0.009271\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 30000: 0.002279\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 35000: 0.007642\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 40000: 0.002782\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 45000: 0.011810\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 50000: 0.004906\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 55000: 0.005797\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 60000: 0.000332\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 65000: 0.010957\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 70000: 0.011513\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 75000: 0.019996\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 80000: 0.012597\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 85000: 0.030370\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 90000: 0.005564\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 95000: 0.011898\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 100000: 0.024709\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 105000: 0.016177\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 110000: 0.056345\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 115000: 0.008044\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 120000: 0.001114\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 125000: 0.006860\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 130000: 0.001674\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 135000: 0.003946\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 140000: 0.001054\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 145000: 0.014802\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 150000: 0.022937\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 155000: 0.003206\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 160000: 0.016598\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 165000: 0.003482\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 170000: 0.001677\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 175000: 0.001885\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 180000: 0.000095\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 185000: 0.002953\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 190000: 0.004774\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 195000: 0.000471\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 200000: 0.020788\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 205000: 0.003095\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 210000: 0.000154\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 215000: 0.000513\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 220000: 0.007919\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 225000: 0.001346\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 230000: 0.000725\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 235000: 0.001846\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 240000: 0.000359\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 245000: 0.000468\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 250000: 0.003211\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 255000: 0.025924\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 260000: 0.009609\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 265000: 0.002607\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 270000: 0.001937\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 275000: 0.025239\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 280000: 0.018923\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 285000: 0.008483\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 290000: 0.001762\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 295000: 0.002608\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 300000: 0.000603\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 305000: 0.000225\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 310000: 0.001363\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 315000: 0.008785\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 320000: 0.042238\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 325000: 0.001159\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 330000: 0.018145\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 335000: 0.000404\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 340000: 0.002427\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 345000: 0.013382\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 350000: 0.001124\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 355000: 0.010649\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 360000: 0.034589\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 365000: 0.002200\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 370000: 0.004386\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 375000: 0.000398\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 380000: 0.029999\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 385000: 0.019010\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 390000: 0.000344\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 395000: 0.008269\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 400000: 0.012276\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 405000: 0.000428\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 410000: 0.000174\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 415000: 0.031511\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 420000: 0.001594\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 425000: 0.005874\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 430000: 0.008158\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 435000: 0.000255\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 440000: 0.020545\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 445000: 0.020751\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 450000: 0.000928\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 455000: 0.000486\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 460000: 0.000127\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 465000: 0.002563\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 470000: 0.009974\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 475000: 0.022054\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 480000: 0.002484\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 485000: 0.007489\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 490000: 0.000239\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 495000: 0.000294\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 500000: 0.002104\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 505000: 0.009116\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 510000: 0.022273\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 515000: 0.015790\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 520000: 0.000749\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 525000: 0.001693\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 530000: 0.000298\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 535000: 0.001170\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 540000: 0.000506\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 545000: 0.001289\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 550000: 0.000191\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 555000: 0.002429\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 560000: 0.001814\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 565000: 0.017271\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 570000: 0.002194\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 575000: 0.012405\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 580000: 0.000851\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 585000: 0.006324\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 590000: 0.002192\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 595000: 0.000310\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 600000: 0.009857\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 605000: 0.017370\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 610000: 0.001713\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 615000: 0.025556\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 620000: 0.050818\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 625000: 0.000076\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 630000: 0.021172\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 635000: 0.001648\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 640000: 0.000825\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 645000: 0.000929\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 650000: 0.045609\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 655000: 0.000769\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 660000: 0.000564\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 665000: 0.002316\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 670000: 0.004000\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 675000: 0.005439\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 680000: 0.000427\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 685000: 0.004585\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 690000: 0.000062\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 695000: 0.001763\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 700000: 0.000117\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 705000: 0.000992\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 710000: 0.000368\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 715000: 0.051099\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 720000: 0.013560\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 725000: 0.004720\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 730000: 0.000330\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 735000: 0.034116\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 740000: 0.001609\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 745000: 0.000541\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.7%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2f405c2f3ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_train_labels\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     _, l, predictions = session.run(\n\u001b[0;32m---> 18\u001b[0;31m       [optimizer, loss, train_prediction], feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Minibatch loss at step %d: %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_steps = 1000001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (y_train.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = x_train[offset:(offset + batch_size), :]\n",
    "    batch_labels = y_train[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 5000 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), y_test))\n",
    "  #print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
