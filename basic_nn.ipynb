{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from pandas import DataFrame, read_csv\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "from tensorflow import nn \n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "############ Read in data\n",
    "#########################\n",
    "\n",
    "data = pickle.load( open( \"kdd99.p\", \"rb\" ) )\n",
    "\n",
    "x_train = data['x_train']\n",
    "x_test = data['x_test']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "(494021, 5)\n",
      "Dos 4107\n",
      "Probe 391458\n",
      "u2r 52\n",
      "r2l 1126\n",
      "TEST\n",
      "(311029, 5)\n",
      "Dos 4166\n",
      "Probe 229853\n",
      "u2r 228\n",
      "r2l 16189\n"
     ]
    }
   ],
   "source": [
    "dos = 0\n",
    "probe = 0\n",
    "u2r = 0\n",
    "r2l = 0\n",
    "\n",
    "for entry in y_train:\n",
    "    if entry[1] == 1:\n",
    "        dos += 1\n",
    "    if entry[2] == 1:\n",
    "        probe += 1\n",
    "    if entry[3] == 1:\n",
    "        u2r += 1\n",
    "    if entry[4] == 1:\n",
    "        r2l += 1\n",
    "\n",
    "print 'TRAIN'\n",
    "print y_train.shape\n",
    "print 'Dos %d'   % dos\n",
    "print 'Probe %d' % probe\n",
    "print 'u2r %d'   % u2r\n",
    "print 'r2l %d'   % r2l\n",
    "\n",
    "dos = 0\n",
    "probe = 0\n",
    "u2r = 0\n",
    "r2l = 0\n",
    "\n",
    "for entry in y_test:\n",
    "    if entry[1] == 1:\n",
    "        dos += 1\n",
    "    if entry[2] == 1:\n",
    "        probe += 1\n",
    "    if entry[3] == 1:\n",
    "        u2r += 1\n",
    "    if entry[4] == 1:\n",
    "        r2l += 1\n",
    "        \n",
    "print 'TEST'\n",
    "print y_test.shape\n",
    "print 'Dos %d'   % dos\n",
    "print 'Probe %d' % probe\n",
    "print 'u2r %d'   % u2r\n",
    "print 'r2l %d'   % r2l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_features = 41 # KDD99 data input (41 features)\n",
    "n_classes = 5 # KDD99 labels (5 types of connection)\n",
    "st_dev = 0.2\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "training_iters = 1000000\n",
    "batch_size = 256\n",
    "display_step = 50\n",
    "display_testing_step = 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_features])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "# Define weights\n",
    "W = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_features, n_hidden_1], stddev=st_dev)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=st_dev)),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_2, n_classes], stddev=st_dev))\n",
    "}\n",
    "\n",
    "b = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.zeros([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_neural_network(x, W, b):\n",
    "    # Hidden layer with RELU activation\n",
    "    hidden_1 = tf.add(tf.matmul(x, W['h1']), b['b1'])\n",
    "    hidden_1 = tf.nn.relu(hidden_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    hidden_2 = tf.add(tf.matmul(hidden_1, W['h2']), b['b2'])\n",
    "    hidden_2 = tf.nn.relu(hidden_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(hidden_2, W['out']) + b['out']\n",
    "    #out_layer = tf.nn.relu(out_layer)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = basic_neural_network(x, W, b)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 12800, Minibatch Loss= 0.801279, Training Accuracy= 0.11328\n",
      "Iter 25600, Minibatch Loss= 0.001868, Training Accuracy= 1.00000\n",
      "Iter 38400, Minibatch Loss= 0.001392, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.67499173)\n",
      "Iter 51200, Minibatch Loss= 1.144663, Training Accuracy= 0.00000\n",
      "Iter 64000, Minibatch Loss= 0.000806, Training Accuracy= 1.00000\n",
      "Iter 76800, Minibatch Loss= 0.013706, Training Accuracy= 1.00000\n",
      "Iter 89600, Minibatch Loss= 0.014102, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.64301723)\n",
      "Iter 102400, Minibatch Loss= 0.000069, Training Accuracy= 1.00000\n",
      "Iter 115200, Minibatch Loss= 0.003060, Training Accuracy= 1.00000\n",
      "Iter 128000, Minibatch Loss= 0.000334, Training Accuracy= 1.00000\n",
      "Iter 140800, Minibatch Loss= 1.194720, Training Accuracy= 0.82031\n",
      "('Validation Accuracy:', 0.78304917)\n",
      "Iter 153600, Minibatch Loss= 0.001093, Training Accuracy= 1.00000\n",
      "Iter 166400, Minibatch Loss= 0.000456, Training Accuracy= 1.00000\n",
      "Iter 179200, Minibatch Loss= 0.000345, Training Accuracy= 1.00000\n",
      "Iter 192000, Minibatch Loss= 0.000260, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.78500396)\n",
      "Iter 204800, Minibatch Loss= 0.000213, Training Accuracy= 1.00000\n",
      "Iter 217600, Minibatch Loss= 0.000187, Training Accuracy= 1.00000\n",
      "Iter 230400, Minibatch Loss= 0.000166, Training Accuracy= 1.00000\n",
      "Iter 243200, Minibatch Loss= 0.000148, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.78458279)\n",
      "Iter 256000, Minibatch Loss= 0.000134, Training Accuracy= 1.00000\n",
      "Iter 268800, Minibatch Loss= 0.000121, Training Accuracy= 1.00000\n",
      "Iter 281600, Minibatch Loss= 0.000110, Training Accuracy= 1.00000\n",
      "Iter 294400, Minibatch Loss= 0.000101, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.78421307)\n",
      "Iter 307200, Minibatch Loss= 0.000093, Training Accuracy= 1.00000\n",
      "Iter 320000, Minibatch Loss= 0.000086, Training Accuracy= 1.00000\n",
      "Iter 332800, Minibatch Loss= 0.000079, Training Accuracy= 1.00000\n",
      "Iter 345600, Minibatch Loss= 0.065608, Training Accuracy= 0.98828\n",
      "('Validation Accuracy:', 0.67187947)\n",
      "Iter 358400, Minibatch Loss= 0.000735, Training Accuracy= 1.00000\n",
      "Iter 371200, Minibatch Loss= 0.211088, Training Accuracy= 0.89062\n",
      "Iter 384000, Minibatch Loss= 0.000003, Training Accuracy= 1.00000\n",
      "Iter 396800, Minibatch Loss= 0.787941, Training Accuracy= 0.35547\n",
      "('Validation Accuracy:', 0.69311863)\n",
      "Iter 409600, Minibatch Loss= 0.000491, Training Accuracy= 1.00000\n",
      "Iter 422400, Minibatch Loss= 0.000075, Training Accuracy= 1.00000\n",
      "Iter 435200, Minibatch Loss= 0.000061, Training Accuracy= 1.00000\n",
      "Iter 448000, Minibatch Loss= 0.000052, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.91343892)\n",
      "Iter 460800, Minibatch Loss= 0.039623, Training Accuracy= 1.00000\n",
      "Iter 473600, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 486400, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 499200, Minibatch Loss= 0.026548, Training Accuracy= 0.99609\n",
      "('Validation Accuracy:', 0.90696043)\n",
      "Iter 512000, Minibatch Loss= 0.000585, Training Accuracy= 1.00000\n",
      "Iter 524800, Minibatch Loss= 0.000185, Training Accuracy= 1.00000\n",
      "Iter 537600, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "Iter 550400, Minibatch Loss= 0.001242, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.7489205)\n",
      "Iter 563200, Minibatch Loss= 0.000657, Training Accuracy= 1.00000\n",
      "Iter 576000, Minibatch Loss= 0.002777, Training Accuracy= 1.00000\n",
      "Iter 588800, Minibatch Loss= 0.008343, Training Accuracy= 1.00000\n",
      "Iter 601600, Minibatch Loss= 0.006592, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.78190458)\n",
      "Iter 614400, Minibatch Loss= 0.000249, Training Accuracy= 1.00000\n",
      "Iter 627200, Minibatch Loss= 0.000011, Training Accuracy= 1.00000\n",
      "Iter 640000, Minibatch Loss= 0.320037, Training Accuracy= 0.94531\n",
      "Iter 652800, Minibatch Loss= 0.000012, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.78655046)\n",
      "Iter 665600, Minibatch Loss= 0.000008, Training Accuracy= 1.00000\n",
      "Iter 678400, Minibatch Loss= 0.000718, Training Accuracy= 1.00000\n",
      "Iter 691200, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "Iter 704000, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.78637362)\n",
      "Iter 716800, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "Iter 729600, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "Iter 742400, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "Iter 755200, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.78634149)\n",
      "Iter 768000, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "Iter 780800, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "Iter 793600, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "Iter 806400, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.78629643)\n",
      "Iter 819200, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "Iter 832000, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "Iter 844800, Minibatch Loss= 0.000516, Training Accuracy= 1.00000\n",
      "Iter 857600, Minibatch Loss= 0.000445, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.78501362)\n",
      "Iter 870400, Minibatch Loss= 0.000058, Training Accuracy= 1.00000\n",
      "Iter 883200, Minibatch Loss= 0.000076, Training Accuracy= 1.00000\n",
      "Iter 896000, Minibatch Loss= 0.000002, Training Accuracy= 1.00000\n",
      "Iter 908800, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.7850554)\n",
      "Iter 921600, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 934400, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 947200, Minibatch Loss= 0.008327, Training Accuracy= 1.00000\n",
      "Iter 960000, Minibatch Loss= 0.000003, Training Accuracy= 1.00000\n",
      "('Validation Accuracy:', 0.9068833)\n",
      "Iter 972800, Minibatch Loss= 0.000001, Training Accuracy= 1.00000\n",
      "Iter 985600, Minibatch Loss= 0.007037, Training Accuracy= 1.00000\n",
      "Iter 998400, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Optimization Finished!\n",
      "Validation accuracy: 0.907915\n",
      "Precision 0.877323722827\n",
      "Recall 0.907915339084\n",
      "f1_score 0.882605925179\n",
      "confusion_matrix\n",
      "[[ 59771      0    822      0      0]\n",
      " [  1524    182   2460      0      0]\n",
      " [  7396     23 222434      0      0]\n",
      " [   225      0      2      1      0]\n",
      " [ 16179      0      9      1      0]]\n",
      "311029\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        offset = (step * batch_size) % (y_train.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        #print offset\n",
    "        batch_x = x_train[offset:(offset + batch_size), :]\n",
    "        batch_y = y_train[offset:(offset + batch_size), :]\n",
    "\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "        \n",
    "        if step % display_testing_step == 0:\n",
    "        \n",
    "            test_len = 20000\n",
    "            test_data = x_test[:]\n",
    "            test_label = y_test[:]\n",
    "            print(\"Validation Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label}))\n",
    "        \n",
    "                \n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    \n",
    "    y_p = tf.argmax(pred, 1)\n",
    "    val_accuracy, y_pred = sess.run([accuracy, y_p], feed_dict={x:x_test, y:y_test})\n",
    "\n",
    "    print \"Validation accuracy:\", val_accuracy\n",
    "    y_true = np.argmax(test_label,1)\n",
    "    print \"Precision\", metrics.precision_score(y_true, y_pred, average ='weighted')\n",
    "    print \"Recall\", metrics.recall_score(y_true, y_pred, average = 'weighted')\n",
    "    print \"f1_score\", metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "    print \"confusion_matrix\"\n",
    "    conf_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "    print metrics.confusion_matrix(y_true, y_pred)\n",
    "    print np.sum(metrics.confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59771      0    822      0      0]\n",
      " [  1524    182   2460      0      0]\n",
      " [  7396     23 222434      0      0]\n",
      " [   225      0      2      1      0]\n",
      " [ 16179      0      9      1      0]]\n",
      "[0.7024031964275221, 0.8878048780487805, 0.9854115812463728, 0.5, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print conf_matrix\n",
    "print [float(conf_matrix[i][i])/(conf_matrix.sum(axis=0)[i]) if conf_matrix.sum(axis=0)[i] > 0 else float(conf_matrix[i][i])/(conf_matrix.sum(axis=0)[i] + 1)  for i,value in enumerate(conf_matrix.sum(axis=0))]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR NORMAL 98.64 %\n",
      "TPR PROBE  4.37 %\n",
      "TPR DOS    96.77 %\n",
      "TPR U2R    0.44 %\n",
      "TPR R2L    0.00 %\n",
      "************\n",
      "FPR NORMAL 1.36 %\n",
      "FPR PROBE  95.63 %\n",
      "FPR DOS    3.23 %\n",
      "FPR U2R    99.56 %\n",
      "FPR R2L    100.00 %\n",
      "************\n",
      "Precision NORMAL 70.24 %\n",
      "Precision PROBE  88.78 %\n",
      "Precision DOS    98.54 %\n",
      "Precision U2R    50.00 %\n",
      "Precision R2L    0.00 %\n",
      "************\n",
      "F1_score NORMAL 82.05 %\n",
      "F1_score PROBE  8.33 %\n",
      "F1_score DOS    97.65 %\n",
      "F1_score U2R    0.87 %\n",
      "F1_score R2L    0.00 %\n"
     ]
    }
   ],
   "source": [
    "tpr = [float(conf_matrix[i][i])/(conf_matrix.sum(axis=1)[i]) if conf_matrix.sum(axis=1)[i] > 0 else float(conf_matrix[i][i])/(conf_matrix.sum(axis=0)[i] + 1)  for i,value in enumerate(conf_matrix.sum(axis=1))]\n",
    "\n",
    "print 'TPR NORMAL %.2f %%' % (tpr[0] * 100)\n",
    "print 'TPR PROBE  %.2f %%' % (tpr[1] * 100)\n",
    "print 'TPR DOS    %.2f %%' % (tpr[2] * 100)\n",
    "print 'TPR U2R    %.2f %%' % (tpr[3] * 100)\n",
    "print 'TPR R2L    %.2f %%' % (tpr[4] * 100)\n",
    "\n",
    "print '************'\n",
    "\n",
    "fpr = [float((conf_matrix.sum(axis=1)[i] - conf_matrix[i][i])) / conf_matrix.sum(axis=1)[i] if conf_matrix.sum(axis=1)[i] > 0 else float((conf_matrix.sum(axis=1)[i] - conf_matrix[i][i])) / (conf_matrix.sum(axis=1)[i] + 1 ) for i,value in enumerate(conf_matrix.sum(axis=1))]\n",
    "\n",
    "print 'FPR NORMAL %.2f %%' % (fpr[0] * 100)\n",
    "print 'FPR PROBE  %.2f %%' % (fpr[1] * 100)\n",
    "print 'FPR DOS    %.2f %%' % (fpr[2] * 100)\n",
    "print 'FPR U2R    %.2f %%' % (fpr[3] * 100)\n",
    "print 'FPR R2L    %.2f %%' % (fpr[4] * 100)\n",
    "\n",
    "print '************'\n",
    "\n",
    "precision = [float(conf_matrix[i][i])/(conf_matrix.sum(axis=0)[i]) if conf_matrix.sum(axis=0)[i] > 0 else float(conf_matrix[i][i])/(conf_matrix.sum(axis=0)[i] + 1)  for i,value in enumerate(conf_matrix.sum(axis=0))]\n",
    "\n",
    "print 'Precision NORMAL %.2f %%' % (precision[0] * 100)\n",
    "print 'Precision PROBE  %.2f %%' % (precision[1] * 100)\n",
    "print 'Precision DOS    %.2f %%' % (precision[2] * 100)\n",
    "print 'Precision U2R    %.2f %%' % (precision[3] * 100)\n",
    "print 'Precision R2L    %.2f %%' % (precision[4] * 100)\n",
    "\n",
    "print '************'\n",
    "\n",
    "f1_score = [2*(precision[i]*tpr[i])/(precision[i]+tpr[i] + 0.0000001) for i in range(len(tpr))]\n",
    "\n",
    "print 'F1_score NORMAL %.2f %%' % (f1_score[0] * 100)\n",
    "print 'F1_score PROBE  %.2f %%' % (f1_score[1] * 100)\n",
    "print 'F1_score DOS    %.2f %%' % (f1_score[2] * 100)\n",
    "print 'F1_score U2R    %.2f %%' % (f1_score[3] * 100)\n",
    "print 'F1_score R2L    %.2f %%' % (f1_score[4] * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
